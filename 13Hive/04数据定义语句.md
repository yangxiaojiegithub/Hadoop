# 数据定义语句

## 数据库

### 新建数据库

```sql
0: jdbc:hive2://node01:10000> create database if not exists mydb location '/user/hivedb';
No rows affected (1.642 seconds)
0: jdbc:hive2://node01:10000> show databases;
+----------------+--+
| database_name  |
+----------------+--+
| default        |
| mydb           |
+----------------+--+

0: jdbc:hive2://node01:10000> show databases like '*db*'; # 模糊查询数据库
+----------------+--+
| database_name  |
+----------------+--+
| mydb           |
+----------------+--+

0: jdbc:hive2://node01:10000> desc database mydb; # 查询数据库的描述信息
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| db_name  | comment  |           location            | owner_name  | owner_type  | parameters  |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| mydb     |          | hdfs://hacluster/user/hivedb  | root        | USER        |             |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+

0: jdbc:hive2://node01:10000> desc database extended mydb; #查看数据库的扩展信息
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| db_name  | comment  |           location            | owner_name  | owner_type  | parameters  |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
| mydb     |          | hdfs://hacluster/user/hivedb  | root        | USER        |             |
+----------+----------+-------------------------------+-------------+-------------+-------------+--+
```

### 修改数据库

使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。数据库的其他元数据信息都是不可更改的，包括数据库名和数据库所在的目录位置

```sql
0: jdbc:hive2://node01:10000> alter database mydb set dbproperties('createtime'='20210127');
No rows affected (0.394 seconds)
0: jdbc:hive2://node01:10000> desc database extended mydb;
+----------+----------+-------------------------------+-------------+-------------+------------------------+--+
| db_name  | comment  |           location            | owner_name  | owner_type  |       parameters       |
+----------+----------+-------------------------------+-------------+-------------+------------------------+--+
| mydb     |          | hdfs://hacluster/user/hivedb  | root        | USER        | {createtime=20210127}  |
+----------+----------+-------------------------------+-------------+-------------+------------------------+--+
1 row selected (2.197 seconds)
```

### 删除数据库

如果数据库不为空，可以采用cascade命令，强制删除

```sql
0: jdbc:hive2://node01:10000> drop database mydb cascade;
No rows affected (4.809 seconds)
0: jdbc:hive2://node01:10000> show databases;
+----------------+--+
| database_name  |
+----------------+--+
| default        |
+----------------+--+
1 row selected (0.171 seconds)
```

## 表

### 建表

```sql
CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
[(col_name data_type [COMMENT col_comment], ...)] 
[COMMENT table_comment] 
[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] 
[CLUSTERED BY (col_name, col_name, ...) 
[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] 
[ROW FORMAT row_format] 
[STORED AS file_format] 
[LOCATION hdfs_path]
```

**字段解释说明**

（1）**CREATE TABLE** 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。

（2）**EXTERNAL**关键字可以让用户创建一个外部表，在建表的同时指向实际数据的路径（LOCATION），Hive创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。

（3）**COMMENT** 为表和列添加注释。

（4）**PARTITIONED BY** 创建分区表

（5）**CLUSTERED BY** 创建分桶表

（6）**SORTED BY** 不常用

（7）ROW FORMAT 

DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]

​    [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] 

  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]

用户在建表的时候可以自定义SerDe或者使用自带的SerDe。如果没有指定ROW FORMAT 或者ROW FORMAT DELIMITED，将会使用自带的SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的SerDe，Hive通过SerDe确定表的具体的列的数据。

SerDe是Serialize/Deserilize的简称，目的是用于序列化和反序列化。

（8）**STORED AS** 指定存储文件类型

常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）

如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。

（9）**LOCATION**  指定表在HDFS上的存储位置。

（10）**LIKE** 允许用户复制现有的表结构，但是不复制数据。

**数据文件准备**

```sql
[root@node02 ~]# vi dept.txt
10	ACCOUNTING	1700
20	RESEARCH	1800
30	SALES	1900
40	OPERATIONS	1700

[root@node02 ~]# vi emp.txt
7369	SMITH	CLERK	7902	1980-12-17	800.00		20
7499	ALLEN	SALESMAN	7698	1981-2-20	1600.00	300.00	30
7521	WARD	SALESMAN	7698	1981-2-22	1250.00	500.00	30
7566	JONES	MANAGER	7839	1981-4-2	2975.00		20
7654	MARTIN	SALESMAN	7698	1981-9-28	1250.00	1400.00	30
7698	BLAKE	MANAGER	7839	1981-5-1	2850.00		30
7782	CLARK	MANAGER	7839	1981-6-9	2450.00		10
7788	SCOTT	ANALYST	7566	1987-4-19	3000.00		20
7839	KING	PRESIDENT		1981-11-17	5000.00		10
7844	TURNER	SALESMAN	7698	1981-9-8	1500.00	0.00	30
7876	ADAMS	CLERK	7788	1987-5-23	1100.00		20
7900	JAMES	CLERK	7698	1981-12-3	950.00		30
7902	FORD	ANALYST	7566	1981-12-3	3000.00		20
7934	MILLER	CLERK	7782	1982-1-23	1300.00		10

[root@node02 ~]# vi stu.txt
1001	ss1
1002	ss2
1003	ss3
1004	ss4
1005	ss5
1006	ss6
1007	ss7
1008	ss8
1009	ss9
1010	ss10
1011	ss11
1012	ss12
1013	ss13
1014	ss14
1015	ss15
1016	ss16
```

#### 内部表和外部表

在删除表的时候，**内部表的元数据和数据会被一起删除**，而外部表只删除元数据，不删除数据。

```sql
# 创建部门表
create external table if not exists dept(
    deptno  int
   ,dname   string
   ,loc     int
)row format delimited fields terminated by '\t';
```

##### 查看表结构

```sql
0: jdbc:hive2://node01:10000> desc formatted dept;
+-------------------------------+-------------------------------------------------------------+-----------------------+--+
|           col_name            |                          data_type                          |        comment        |
+-------------------------------+-------------------------------------------------------------+-----------------------+--+
| # col_name                    | data_type                                                   | comment               |
|                               | NULL                                                        | NULL                  |
| deptno                        | int                                                         |                       |
| dname                         | string                                                      |                       |
| loc                           | int                                                         |                       |
|                               | NULL                                                        | NULL                  |
| # Detailed Table Information  | NULL                                                        | NULL                  |
| Database:                     | default                                                     | NULL                  |
| Owner:                        | root                                                        | NULL                  |
| CreateTime:                   | Sat Jan 30 04:42:55 CST 2021                                | NULL                  |
| LastAccessTime:               | UNKNOWN                                                     | NULL                  |
| Protect Mode:                 | None                                                        | NULL                  |
| Retention:                    | 0                                                           | NULL                  |
| Location:                     | hdfs://hacluster/user/hivedb/warehouse/dept                 | NULL                  |
| Table Type:                   | EXTERNAL_TABLE                                              | NULL                  |
| Table Parameters:             | NULL                                                        | NULL                  |
|                               | EXTERNAL                                                    | TRUE                  |
|                               | transient_lastDdlTime                                       | 1611952975            |
|                               | NULL                                                        | NULL                  |
| # Storage Information         | NULL                                                        | NULL                  |
| SerDe Library:                | org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe          | NULL                  |
| InputFormat:                  | org.apache.hadoop.mapred.TextInputFormat                    | NULL                  |
| OutputFormat:                 | org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat  | NULL                  |
| Compressed:                   | No                                                          | NULL                  |
| Num Buckets:                  | -1                                                          | NULL                  |
| Bucket Columns:               | []                                                          | NULL                  |
| Sort Columns:                 | []                                                          | NULL                  |
| Storage Desc Params:          | NULL                                                        | NULL                  |
|                               | field.delim                                                 | \t                    |
|                               | serialization.format                                        | \t                    |
+-------------------------------+-------------------------------------------------------------+-----------------------+--+
```

##### 内外部表相互转换

外转内

```sql
alter table dept set tblproperties('EXTERNAL'='FALSE');
| Table Type:                   | MANAGED_TABLE      # 内部表
```

内转外

```sql
alter table dept set tblproperties('EXTERNAL'='TRUE');
| Table Type:                   | EXTERNAL_TABLE     # 外部表      
```

注意：('EXTERNAL'='TRUE')和('EXTERNAL'='FALSE')为固定写法，区分大小写

#### 分区表

Hive 中的分区就是分目录，在WHERE条件里用分区字段筛选，可以提高查询效率。 注意分区字段不能和表里已有的字段一样，不然会报错 Column repeated in partitioning columns。

##### 建分区表

```sql
# 按 pt_d 为分区字段创建员工表, 分区字段任意
create external table if not exists emp(
    empno       int
   ,ename       string
   ,job         string
   ,mgr         int
   ,hiredate    string
   ,sal         double
   ,comm        double
   ,deptno      int
)
partitioned by (pt_d int)
row format delimited fields terminated by '\t';
```

##### 添加分区

```sql
alter table emp add partition(pt_d='20210129');
```

![](./doc/05.png)

同时给表添加多个分区

```sql
alter table emp add partition(pt_d='20210127') partition(pt_d='20210128');
```

##### 删除分区

```sql
alter table emp drop partition(pt_d='20210129');
```

删除多个分区

```sql
alter table emp drop partition(pt_d='20210127'),partition(pt_d='20210128');
```

##### 查看分区

```sql
show partitions emp;
```

##### 多级分区

```sql
create external table if not exists ods_emp
(
   empno       int
   ,ename       string
   ,job         string
   ,mgr         int
   ,hiredate    string
   ,sal         double
   ,comm        double
   ,deptno      int
)
partitioned by (pt_m String, pt_d String)
row format delimited fields terminated by '\t';
```

##### 修复分区

```sql
msck repair table emp;
```

#### 分桶表

分区针对的是数据的存储路径；分桶针对的是数据文件。

分区会增加一个分区字段，分桶是对表里的数据进行分桶，需要指明分桶的个数

分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。

分桶是将数据集分解成更容易管理的若干部分的另一个技术。

**要使分桶表生效，必须把普通表的数据倒数到分桶表中**

新建一张普通表，表字段和分桶表一样，并导入数据

```sql
create table stu_shadow
(
    id int
   ,name string
)
row format delimited fields terminated by '\t';
hdfs dfs -put stu.txt /user/hivedb/warehouse/stu_shadow
```

##### 建分桶表

```sql
create table stu_buck
(
    id int
   ,name string
)
clustered by(id) into 4 buckets
row format delimited fields terminated by '\t';
```

##### 设置分桶属性

```sql
set hive.enforce.bucketing=true;
set mapreduce.job.reduces=-1;
```

##### 导入普通表的数据到分桶表

```sql
insert into table stu_buck select id, name from stu_shadow;
```

##### 查看分桶

```sql
0: jdbc:hive2://node01:10000> select * from stu_buck;
+--------------+----------------+--+
| stu_buck.id  | stu_buck.name  |
+--------------+----------------+--+
| 1016         | ss16           |
| 1012         | ss12           |
| 1008         | ss8            |
| 1004         | ss4            |
| 1009         | ss9            |
| 1005         | ss5            |
| 1001         | ss1            |
| 1013         | ss13           |
| 1010         | ss10           |
| 1002         | ss2            |
| 1006         | ss6            |
| 1014         | ss14           |
| 1003         | ss3            |
| 1011         | ss11           |
| 1007         | ss7            |
| 1015         | ss15           |
+--------------+----------------+--+
# 观察id可以发现 1到4行对4取余为0，5到8行对4取余为1，9到12行对4取余为2，13到16行对四取余为3
```

![](./doc/06.png)



##### 分桶抽样查询

对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。

分桶查询表stu_buck中的数据

```sql
0: jdbc:hive2://node01:10000> select * from stu_buck tablesample(bucket 1 out of 4 on id);
+--------------+----------------+--+
| stu_buck.id  | stu_buck.name  |
+--------------+----------------+--+
| 1016         | ss16           |
| 1012         | ss12           |
| 1008         | ss8            |
| 1004         | ss4            |
+--------------+----------------+--+
4 rows selected (1.924 seconds)
0: jdbc:hive2://node01:10000> select * from stu_buck tablesample(bucket 1 out of 8 on id);
+--------------+----------------+--+
| stu_buck.id  | stu_buck.name  |
+--------------+----------------+--+
| 1016         | ss16           |
| 1008         | ss8            |
+--------------+----------------+--+
2 rows selected (0.268 seconds)
```

注：tablesample是抽样语句，语法：TABLESAMPLE(BUCKET x OUT OF y) 。

y必须是table总bucket数的倍数或者因子。hive根据y的大小，决定抽样的比例。例如，table总共分了4份，当y=4时，抽取(4/4=)1个bucket的数据，当y=8时，抽取(4/8=)1/2个bucket的数据。

x表示从哪个bucket开始抽取，如果需要取多个分区，以后的分区号为当前分区号加上y。例如，table总bucket数为4，tablesample(bucket 1 out of 2)，表示总共抽取（4/2=）2个bucket的数据，抽取第1(x)个和第3(x+y)个bucket的数据。

注意：x的值必须小于等于y的值，否则

FAILED: SemanticException [Error 10061]: Numerator should not be bigger than denominator in sample clause for table stu_buck

### 改表

#### 重命名表

```sql
alter table ods_emp rename to dwd_emp;
```

#### 新增修改列

```sql
alter table dwd_emp add columns(id String, name String); # 新增列
alter table dwd_emp change column name sp_name String; # 修改列名
alter table dwd_emp change column sp_name sp_name int; # 修改列类型
```

#### 追加列

```sql
alter table dwd_emp add columns(no String); # 第一步新增列
alter table dwd_emp change column no no String after id; # 第二步将新增的列改到指定的位置
```

#### replace

注：ADD是新增字段， 字段位置再所有列后面(position 列前)， **REPLACE** 则是表示替换表中的所有字段。

```sql
0: jdbc:hive2://node01:10000> alter table dwd_emp replace columns(id String);
No rows affected (0.353 seconds)
0: jdbc:hive2://node01:10000> desc dwd_emp;
+--------------------------+-----------------------+-----------------------+--+
|         col_name         |       data_type       |        comment        |
+--------------------------+-----------------------+-----------------------+--+
| id                       | string                |                       |
| pt_m                     | string                |                       |
| pt_d                     | string                |                       |
|                          | NULL                  | NULL                  |
| # Partition Information  | NULL                  | NULL                  |
| # col_name               | data_type             | comment               |
|                          | NULL                  | NULL                  |
| pt_m                     | string                |                       |
| pt_d                     | string                |                       |
+--------------------------+-----------------------+-----------------------+--+
```

### 清空表

只能清空内部表

```sql
truncate table 表名
```
